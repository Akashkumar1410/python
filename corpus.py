import nltk
from nltk.corpus import stopwords
from nltk.tokenize import sent_tokenize, word_tokenize

nltk.download('punkt')
nltk.download('stopwords')

# Sample corpus with special symbols and brackets
corpus = """ğŸ“ğŸ›ï¸ My university, â­ï¸ğ— ğ˜† ğ—¨ğ—»ğ—¶ğ˜ƒğ—²ğ—¿ğ˜€ğ—¶ğ˜ğ˜†â­ï¸, is a place of ğŸ“šğŸ”¬âœ¨knowledge and discovery, where every day is a new adventure. Located in the heart of ğŸŒ†ğŸŒ³ğŸï¸, our campus is a vibrant hub of ğŸŒŸğŸ’¡ğŸ’¼learning and innovation. With a diverse community of ğŸ§‘â€ğŸ“ğŸ‘©â€ğŸ«ğŸ‘¨â€ğŸ”¬students, ğŸŒğŸŒğŸŒfaculty, and ğŸŒğŸ¤ğŸŒŸstaff from all corners of the world, we embrace and celebrate our differences, fostering an environment of ğŸ¤ğŸŒˆğŸ‰inclusivity and mutual respect.

At â­ï¸ğ— ğ˜† ğ—¨ğ—»ğ—¶ğ˜ƒğ—²ğ—¿ğ˜€ğ—¶ğ˜ğ˜†â­ï¸, we are committed to ğŸ“šğŸ§ ğŸŒ±academic excellence, providing a wide range of ğŸ“–ğŸ“ŠğŸ”programs and resources to help students reach their full potential. Our state-of-the-art ğŸ«ğŸ”¬ğŸ–¥ï¸facilities and ğŸŒ†ğŸï¸ğŸ›ï¸beautiful campus create the perfect backdrop for a rich and fulfilling educational experience.

But it's not just about the classroom; we also value ğŸ’¼ğŸ¤ğŸŒ±community engagement and ğŸŒŸğŸ†ğŸŒglobal awareness. Students at â­ï¸ğ— ğ˜† ğ—¨ğ—»ğ—¶ğ˜ƒğ—²ğ—¿ğ˜€ğ—¶ğ˜ğ˜†â­ï¸ have countless opportunities to get involved in ğŸŒğŸŒ±ğŸ¤extracurricular activities, from ğŸ€ğŸ¶ğŸ­sports and ğŸ¨ğŸ‰ğŸ¤arts to ğŸ’¼ğŸŒğŸŒinternships and ğŸŒ±ğŸ“£ğŸŒŸvolunteer work.

In conclusion, â­ï¸ğ— ğ˜† ğ—¨ğ—»ğ—¶ğ˜ƒğ—²ğ—¿ğ˜€ğ—¶ğ˜ğ˜†â­ï¸ is not just a university; it's a place where dreams are nurtured, knowledge is cherished, and friendships are forged. It's a symbol of ğŸ“šğŸŒŸğŸŒˆhope and a beacon of ğŸ§ ğŸ’¡ğŸŒintellectual growth in an ever-changing world.

"""


sentences = sent_tokenize(corpus)


stop_words = set(stopwords.words("english"))
filtered_corpus = []

for sentence in sentences:
    words = word_tokenize(sentence)
    filtered_words = [word.lower() for word in words if word.lower() not in stop_words and word.isalpha()]
    if filtered_words:
        filtered_sentence = " ".join(filtered_words)
        filtered_corpus.append(filtered_sentence)


output_paragraph = " ".join(filtered_corpus)

# Display the paragraph
print(output_paragraph)
